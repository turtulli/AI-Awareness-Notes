# AI Awareness Notes

## AI Story
Yuval Noah Harari argues that humans became humans as they gathered around stories. Telling stories gave rise to a collective identity, a sense of purpose, and a foundation for cooperation. 

Now we have a new story, Artificial Intelligence (AI).

![](/attachments/brain-and-neural-network.png)

Science is not as compelling as stories...

The brain is much more complex than a network of neurons, even though neurons themselves are relatively simple. AI Neural Networks are inspired by the structure of the human brain's network of neurons, but they are vastly simplified.

Geoffrey Hinton, the godfather of AI, successfully advocated for a focus on solving specific tasks that work **mathematically**, rather than strictly mimicking the intricacies of biological neural networks when developing artificial neural networks (ANNs).

![](/attachments/neural-networks-and-mathematical-model.png)

Fei-Fei Li says that when building an airplane, it is aerodynamics and physics that govern the process of flying. If we ask for similar laws in the relationship between AI and the brain, it still feels like we are before Newton's laws. 

## AI Advantages
Our brain consumes 30 watts when learning, while an AI like ChatGPT consumes 30 megawatts when training (learning). You can find other numbers online, but let's just focus on these numbers. The order of magnitude of the power used is enormous, 1 to 1 million. But while this ratio is interesting, I don't think we are really impressed by that. I think, we humans have surpassed that point since the invention of the steam engine, which propelled the industrial revolution and the power of the machines took over hand labor.

So, we can naturally imagine that there are some very powerful computers, and a lot of them, working intensively to process any data they can find in the world. This is actually the core advantage of AI over the human brain: the scale at which AI can operate.

We also know that while biological intelligence is mortal, digital intelligence is immortal. We can copy ChatGPT to some other computers.

What is surprising, though, is that digital intelligence may have a better learning algorithm than the brain. 

## AI Learning Algorithm
Where is the Life we have lost in living?</br>
Where is the wisdom we have lost in knowledge?</br>
Where is the knowledge we have lost in information?</br>
― T.S. Eliot, The Rock (1934)

These lines by T.S. Eliot are believed to have originated the idea of the DIKW (Data → Information → Knowledge → Wisdom) relationship, which has been a part of the language of information science for many years.

![](/attachments/DIKW-pyramid.png)


There are two main approaches to AI: a bottom-up approach, as suggested by the DIKW pyramid, and, by analogy, a top-down approach.

The bottom-up approach is implemented through artificial neural networks; ChatGPT employs this approach. On the other hand, Siri initially adopted a top-down approach and later incorporated features of the bottom-up approach.

A better way to understand what AI is about is to engage with it. For the broader audience, the most effective approach might involve just reading and contemplating AI concepts. Let's ask ourselves a simple question: when do I learn more (can I rate it?!) about AI, when I consume a lot of tech news about AI, or when I read articles that explain the principles of AI? 

People have mental models of how the world works; a kind of internal simulator that simulates the interesting aspect of the case we want to assess, enabling us to understand. For someone familiar with charts, the DIKW pyramid can be incredibly useful. For others working in media, tech news may be more helpful, and they might discover intriguing aspects of AI that a tech article didn't consider or that were out of scope. Both groups, however, are constructing new models based on their prior ones, combining their existing 'data/information' with new 'data/information,' and transforming them into AI knowledge. 

We can further explain that what constitutes knowledge for one model could be data/information for another model and so on. In any case, we need to find ways to nurture curiosity and remain receptive to AI's journey toward mimicking human intelligence.

This idea of data transformation and reshaping from layer to layer is important in understanding how AI works; like energy transformation is key in physics.

Let's now see how top-down and bottom-up approaches work in practice.

The early success of AI in the 2000s followed the top-down approach. Researchers focused on knowledge extraction from human beings and representing it in a computer-readable form. To transfer knowledge to a computer, you have to find a way to represent it. This is achieved through reasoning and logic, and symbols are eventually used to operate with logic.

A simple example of how you can extract knowledge using logic and symbols might look like this:

![](/attachments/and-or-tree.png)

This image can effectively illustrate how we can determine an animal based on its physical characteristics. However, does it perform well in practice? Can this model solve the following riddle?

'I am a creature of stripes, adorned like a canvas of art,
With black and white in harmony, running free with all my heart.
In the African grasslands, where the sun kisses the earth,
I roam with my herd, my beauty, and my worth.
What am I?' (Answer: Zebra)

The creative and metaphorical nature of the riddle makes it difficult for symbolic AI to interpret the poetic language and connect it to the specific answer 'zebra'. While the inability to solve a riddle doesn't define the quality of an AI model, it does highlight the limitations of the model.

The top-down approach, such as symbolic AI, excels at modeling precise and consistent knowledge, such as automating the movement and placement of items in a warehouse.

The main challenge with this approach is that wisdom, knowledge, and concepts are challenging to define scientifically, and creating highly accurate descriptions of anything is impossible.

These top-down models are effective managers of the knowledge we can extract from human life experiences and feed to them. However, they lack the ability to create their own artificial experiences.

So, if we can't rationally define what a zebra is, how can a computer define how to recognize a picture of a zebra?

The answer lies in artificial neural networks (ANNs), or as it's more commonly referred to in AI, deep learning.

**bottom-up approach / ANNs**



